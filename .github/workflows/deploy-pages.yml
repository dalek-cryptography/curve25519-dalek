# Fast website deployment - callgraph is loaded from cache
name: Deploy Website to GitHub Pages

on:
  push:
    branches:
      - main

    paths:
      - 'docs/**'
      - 'scripts/update_stats_history.py'
      - 'scripts/plot_*.py'
      - 'scripts/csv_to_markdown.py'
      - '.github/workflows/deploy-pages.yml'
      - 'curve25519-dalek/src/**/*.rs'  # Dashboard analyzes Rust files
      - 'curve25519-dalek/build.rs'
      # Note: Callgraph is generated separately by generate-callgraph.yml
      # and cached. This workflow deploys immediately using cached callgraph.
      # Note: certifications.json is stored in the certifications-data branch
      # and fetched directly by script.js from raw.githubusercontent.com
      # Note: specs_data.json is now generated by probe-verus specs-data
      # Note: curve25519_functions.csv is now generated by probe-verus tracked-csv
      # (replacing extract_specs.py, analyze_verus_specs_proofs.py, and functions_to_track.csv)
  workflow_dispatch:

# Sets permissions for GitHub Pages deployment
permissions:
  contents: read
  pages: write
  id-token: write

# Allow only one concurrent deployment
concurrency:
  group: "pages"
  cancel-in-progress: false

jobs:
  # Job 1: Build the dashboard
  build-dashboard:
    name: Build Dashboard
    runs-on: ubuntu-latest
    steps:
      - name: Checkout
        uses: actions/checkout@v4
        with:
          fetch-depth: 0  # Full git history needed for temporal charts

      - name: Setup Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.11'

      - name: Install Python dependencies
        run: |
          pip install matplotlib pandas gitpython beartype

      - name: Install uv
        run: |
          curl -LsSf https://astral.sh/uv/install.sh | sh
          echo "$HOME/.cargo/bin" >> $GITHUB_PATH

      - name: Setup probe-verus
        uses: ./.github/actions/setup-probe-verus

      - name: Generate tracked functions CSV
        run: |
          probe-verus tracked-csv curve25519-dalek/src --output outputs/curve25519_functions.csv \
            --github-base-url "https://github.com/Beneficial-AI-Foundation/dalek-lite/blob/main/curve25519-dalek/src/"

      - name: Update stats history
        run: |
          # Try to fetch existing history from deployed site and update
          # If this fails, regenerate from git history (fallback with max commits for full history)
          python3 scripts/update_stats_history.py \
            --fetch-url https://beneficial-ai-foundation.github.io/dalek-lite/outputs/stats_history.jsonl \
            --fill-missing \
            --since 2025-10-09 \
            --max-commits 10000 \
            --min-entries 100 \
            --max-gap-days 14 || \
          (echo "Warning: Stats history fetch failed, regenerating from git..." && \
           if [ -f outputs/curve25519_functions.csv ]; then \
             python3 scripts/update_stats_history.py --since 2025-10-09 --max-commits 10000 --fill-missing; \
           else \
             echo "Error: CSV file missing, skipping stats history update"; \
             touch outputs/stats_history.jsonl; \
           fi)

      - name: Generate charts
        run: |
          python3 scripts/plot_progress.py
          python3 scripts/plot_progress_over_time.py
          python3 scripts/plot_csv_preview.py

      - name: Generate specs data
        run: |
          probe-verus specs-data curve25519-dalek/src --output docs/specs_data.json \
            --github-base-url "https://github.com/Beneficial-AI-Foundation/dalek-lite/blob/main/curve25519-dalek/src/" \
            --libsignal-entrypoints .github/data/focus_dalek_entrypoints.json

      - name: Copy charts and CSV to docs
        run: |
          mkdir -p docs/outputs
          cp outputs/verification_funnel.png docs/outputs/
          cp outputs/absolute_counts_over_time.png docs/outputs/
          cp outputs/module_breakdown.png docs/outputs/
          cp outputs/csv_preview.png docs/outputs/
          cp outputs/curve25519_functions.csv docs/outputs/
          cp outputs/metadata.json docs/outputs/
          cp outputs/stats.json docs/outputs/
          cp outputs/stats_history.jsonl docs/outputs/

      - name: Upload dashboard artifact
        uses: actions/upload-artifact@v4
        with:
          name: dashboard
          path: docs
          retention-days: 1

  # Job 2: Merge dashboard and cached callgraph, then deploy
  deploy:
    name: Deploy to GitHub Pages
    needs: build-dashboard
    runs-on: ubuntu-latest
    
    environment:
      name: github-pages
      url: ${{ steps.deployment.outputs.page_url }}
    
    steps:
      - name: Download dashboard
        uses: actions/download-artifact@v4
        with:
          name: dashboard
          path: site

      # Restore callgraph from cache (generated by generate-callgraph.yml workflow)
      - name: Restore callgraph from cache
        id: cache-callgraph
        uses: actions/cache/restore@v4
        with:
          path: callgraph
          key: callgraph-nevermatch  # Won't match, falls through to restore-keys
          restore-keys: callgraph-

      - name: Copy callgraph to site directory
        run: |
          if [ -f callgraph/index.html ]; then
            echo "✓ Callgraph restored from cache"
            mkdir -p site/callgraph
            cp -r callgraph/* site/callgraph/
          else
            echo "⚠ Callgraph not found in cache (expected on first run or if cache expired)"
            echo "Deployment will continue without callgraph"
          fi

      - name: List final site structure
        run: |
          echo "=== Final site structure ==="
          find site -type f | head -50
          echo "..."

      - name: Setup Pages
        uses: actions/configure-pages@v4

      - name: Upload combined artifact
        uses: actions/upload-pages-artifact@v3
        with:
          path: site

      - name: Deploy to GitHub Pages
        id: deployment
        uses: actions/deploy-pages@v4
